{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T13:45:16.920482Z","iopub.execute_input":"2025-05-08T13:45:16.920782Z","iopub.status.idle":"2025-05-08T13:45:18.864267Z","shell.execute_reply.started":"2025-05-08T13:45:16.920752Z","shell.execute_reply":"2025-05-08T13:45:18.863206Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/original-lner-dataset/fold2.json\n/kaggle/input/original-lner-dataset/fold1.json\n/kaggle/input/original-lner-dataset/fold3.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\nimport os\n\n# Define the label mapping\nlabel_mapping = {\n    0: \"APP\",        1: \"RESP\",\n    2: \"A.COUNSEL\",  3: \"R.COUNSEL\",\n    4: \"JUDGE\",      5: \"WIT\",\n    6: \"AUTH\",       7: \"COURT\",\n    8: \"STAT\",       9: \"PREC\",\n    10: \"DATE\",      11: \"CASENO\"\n}\n\ndef process_json_file(input_path, output_path):\n    \"\"\"\n    Reads a JSON file with multiple documents, converts numeric labels to text,\n    extracts entity snippets, and writes the transformed data to a new JSON file.\n    \"\"\"\n    with open(input_path, 'r', encoding='utf-8') as f_in:\n        documents = json.load(f_in)\n\n    transformed_docs = []\n\n    for doc in documents:\n        doc_id = doc['id']\n        text = doc['text']\n        new_labels = []\n\n        for span in doc['spans']:\n            start, end = span['start'], span['end']\n            label_num = span['label']\n            label_name = label_mapping.get(label_num, str(label_num))\n            extracted_text = text[start:end]\n            new_labels.append([start, end, label_name, extracted_text])\n\n        new_labels.sort(key=lambda x: x[0])\n\n        transformed_doc = {\n            \"id\": doc_id,\n            \"text\": text,\n            \"labels\": new_labels\n        }\n        transformed_docs.append(transformed_doc)\n\n    output_data = {\n        \"version\": \"1.0.0\",\n        \"data\": transformed_docs\n    }\n\n    with open(output_path, 'w', encoding='utf-8') as f_out:\n        json.dump(output_data, f_out, ensure_ascii=False, indent=4)\n\n    print(f\"Processed {len(documents)} documents from {input_path} -> {output_path}\")\n\n\ninput_files = [\n   \"/kaggle/input/original-lner-dataset/fold1.json\",\n   \"/kaggle/input/original-lner-dataset/fold2.json\",\n   \"/kaggle/input/original-lner-dataset/fold3.json\"\n]\n\nfor input_path in input_files:\n    base_name = os.path.basename(input_path)\n    output_name = f\"/kaggle/working/{base_name}\"\n    process_json_file(input_path=input_path, output_path=output_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T13:47:41.715120Z","iopub.execute_input":"2025-05-08T13:47:41.715412Z","iopub.status.idle":"2025-05-08T13:47:41.912496Z","shell.execute_reply.started":"2025-05-08T13:47:41.715388Z","shell.execute_reply":"2025-05-08T13:47:41.911589Z"}},"outputs":[{"name":"stdout","text":"Processed 35 documents from /kaggle/input/original-lner-dataset/fold1.json -> /kaggle/working/fold1.json\nProcessed 35 documents from /kaggle/input/original-lner-dataset/fold2.json -> /kaggle/working/fold2.json\nProcessed 35 documents from /kaggle/input/original-lner-dataset/fold3.json -> /kaggle/working/fold3.json\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}